{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf62e0f6",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d0788",
   "metadata": {},
   "source": [
    "### Typical workflow\n",
    "Define Dataset, Dataloader -> Define Model -> Train -> Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bc7922",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cfcf771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f36ab04bf524e209f751d7308d4cb54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62f8eb9ec6f4072bd33bb269ed019c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ad5100ebf947b9858b037b33ce223e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c0e6b63af64ddbbd42fdc0bde55d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryaman/miniconda3/envs/fastai/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448216815/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as tf\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=tf.ToTensor())\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=tf.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd66fa8",
   "metadata": {},
   "source": [
    "#### Dataset stores the samples and their corresponding labels while DataLoader wraps an iterable around the dataset\n",
    "\n",
    "- Batch size = number of datasamples propogated before parameters are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "adbafc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dl = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5372f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Using the dataloader\n",
    "\n",
    "loader = enumerate(train_dl)\n",
    "batch, (x,y) = next(loader)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4c498b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x[0][0], cmap='gray')\n",
    "plt.show()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91847048",
   "metadata": {},
   "source": [
    "### Model (MLP)\n",
    "- Model does not return probabilities in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "913e74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 10)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a05f88bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10]) tensor([[0.0000, 0.0000, 0.0000, 0.1040, 0.0000, 0.0000, 0.0000, 0.0487, 0.0000,\n",
      "         0.0000]])\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "# Looking at models outputs using a random input tensor\n",
    "def test():\n",
    "    model = MLP()\n",
    "    x = torch.randn(1, 1, 28, 28)\n",
    "    with torch.no_grad():\n",
    "        y = model(x)\n",
    "    print(y.shape, y)\n",
    "    \n",
    "    # evaluating probabilites\n",
    "    prob = torch.nn.functional.softmax(y, dim=1)\n",
    "    print(torch.argmax(prob))\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce84575",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "#### Hyperparameters\n",
    "- adjustable params that you control optimisation process\n",
    "\n",
    "- Epochs = number of times to iterate over dataset\n",
    "- Learning Rate= how much to update the model paramters at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc1dbb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "EPOCHS = 20\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = MLP()\n",
    "optimizer = optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b92b5d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device=DEVICE)\n",
    "        y = y.to(device=DEVICE)\n",
    "        #compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # backpropogation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch%200 ==0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device=DEVICE)\n",
    "            y = y.to(device=DEVICE)\n",
    "            \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "17db5cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "loss: 0.582555  [    0/60000]\n",
      "loss: 0.343390  [12800/60000]\n",
      "loss: 0.308387  [25600/60000]\n",
      "loss: 0.565532  [38400/60000]\n",
      "loss: 0.270010  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.341385 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device=DEVICE)\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n ++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    train_loop(train_dl, model, loss_fn, optimizer)\n",
    "    test_loop(test_dl, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb01749f",
   "metadata": {},
   "source": [
    "## Predicting classes\n",
    "- Using our trained model to predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e05b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open('./topredict.jpeg').convert(\"L\")\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b06efdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pytorch.org/vision/stable/transforms.html\n",
    "transform = tf.Compose([\n",
    "    tf.ToTensor(),\n",
    "    tf.Resize((28,28))\n",
    "])\n",
    "\n",
    "image_tensor = transform(image)\n",
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "807b7e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "image_tensor = image_tensor.resize(1, 1, 28, 28)\n",
    "\n",
    "pred = model(image_tensor)\n",
    "    \n",
    "print(torch.argmax(pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
